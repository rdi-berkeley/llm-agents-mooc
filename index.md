---
layout: default
title: "Large Language Model Agents"
permalink: /f24
redirect_from:
 - /
---

### Prospective Students

- To sign up for the course, please fill in this <a href="https://forms.gle/svSoNhKcGFjxup989">form</a>.
- For course discussion and questions, please join the MOOC channel at <a href="https://discord.gg/NWVpQ9rBvd">LLM Agents Discord</a>.

## Course Staff

<table>
<tbody>
<tr>
<td>Instructor</td>
<td>Co-instructor</td>
</tr>
<tr>
<td><img src="assets/dawn-berkeley.jpg" height=200/></td>
<td><img src="assets/XinyunChen.jpg" height=200/></td>
</tr>
<tr>
<td><a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></td>
<td>Xinyun Chen</td>
<tr>
<td>Professor, UC Berkeley</td>
<td>Research Scientist, Google DeepMind</td>
</tr>
</tr>
</tbody>
</table>

## Guest Speakers

<table>
<tbody>
<tr>
<td><img src="assets/Denny Zhou.jpeg" height=150/></td>
<td><img src="assets/Shunyu Yao.jpeg" height=150/></td>
<td><img src="assets/Chi Wang.jpg" height=150/></td>
<td><img src="assets/Jerry Liu.jpg" height=150/></td>
</tr>

<tr>
<td>Denny Zhou</td>
<td>Shunyu Yao</td>
<td>Chi Wang</td>
<td>Jerry Liu</td>
</tr>
 
<tr>
<td><img src="assets/Google Deepmind.png" height=40/></td>
<td><img src="assets/openai.png" height=40/></td>
<td><img src="assets/Google Deepmind.png" height=40/></td>
<td><img src="assets/LlamaIndex.png" height=50/></td>
</tr>

</tbody>
</table>

<table>
<tbody>

<tr>
<td><img src="assets/Burak Gokturk.png" height=150/></td>
<td><img src="assets/Omar Khattab.jpg" height=150/></td>
<td><img src="assets/Graham Neubig.jpg" height=150/></td>
<td><img src="assets/Nicolas Chapados.jpg" height=150/></td>
</tr>

<tr>
<td>Burak Gokturk</td>
<td>Omar Khattab</td>
<td>Graham Neubig</td>
<td>Nicolas Chapados</td>
</tr>
 
<tr>
<td><img src="assets/Google.jpg" height=50/></td>
<td><img src="assets/databricks.png" height=40/></td>
<td><img src="assets/CMU.png" height=50/></td>
<td><img src="assets/servicenow.png" height=40/></td>
</tr>

</tbody>
</table>


<table>
<tbody>

<tr>
<td><img src="assets/Yuandong Tian.png" height=150/></td>
<td><img src="assets/Jim Fan.jpeg" height=150/></td>
<td><img src="assets/Percy Liang.jpeg" height=150/></td>
<td><img src="assets/Ben Mann.jpeg" height=150/></td>
</tr>

<tr>
<td>Yuandong Tian</td>
<td>Jim Fan</td>
<td>Percy Liang</td>
<td>Ben Mann</td>
</tr>
 
<tr>
<td><img src="assets/meta ai.jpeg" height=40/></td>
<td><img src="assets/nvidia.png" height=40/></td>
<td><img src="assets/stanford.png" height=40/></td>
<td><img src="assets/Anthropic.png" height=18/></td>
</tr>

</tbody>
</table>

## Course Description

Large language models (LLMs) have revolutionized a wide range of domains. In particular, LLMs have been developed as agents to interact with the world and handle various tasks. With the continuous advancement of LLM techniques, LLM agents are set to be the upcoming breakthrough in AI, and they are going to transform the future of our daily life with the support of intelligent task automation and personalization. In this course, we will first discuss fundamental concepts that are essential for LLM agents, including the foundation of LLMs, essential LLM abilities required for task automation, as well as infrastructures for agent development. We will also cover representative agent applications, including code generation, robotics, web automation, medical applications, and scientific discovery. Meanwhile, we will discuss limitations and potential risks of current LLM agents, and share insights into directions for further improvement. Specifically, this course will include the following topics:
- Foundation of LLMs
- Reasoning
- Planning, tool use
- LLM agent infrastructure
- Retrieval-augmented generation
- Code generation, data science
- Multimodal agents, robotics
- Evaluation and benchmarking on agent applications
- Privacy, safety and ethics
- Human-agent interaction, personalization, alignment
- Multi-agent collaboration

## Syllabus

| Date   | Guest Lecture | Supplemental Readings | 
|--------|-------|-------|
| Sept 9 | **LLM Reasoning** <br> Denny Zhou, Google DeepMind | - [Chain-of-Thought Reasoning Without Prompting](https://arxiv.org/abs/2402.10200) <br> - [LLMs Cannot Self-Correct Reasoning Yet](https://arxiv.org/abs/2310.01798) <br> - [Premise Order Matters in Reasoning with LLMs](https://arxiv.org/abs/2402.08939) <br> - [Chain-of-Thought Transformers Solve Inherently Serial Problems](https://arxiv.org/abs/2402.12875) |   
| Sept 16 | **LLM agents: brief history and overview** <br> Shunyu Yao, OpenAI | - [WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents](https://arxiv.org/abs/2207.01206) <br> - [ReAct: Synergizing Reasoning and Acting in Language Models.](https://arxiv.org/abs/2210.03629)  |          
| Sept 23 | **Introduction to Agentic AI and AutoGen** <br> Chi Wang, AutoGen-AI <br> **The Future of Knowledge Assistants** <br> Jerry Liu, LlamaIndex |  |          
| Sept 30 | **Trends of Generative AI with Enterprises, Key blocks to build successful agents** <br> Burak Gokturk, Google |  |          
| Oct 7 | **Compound AI Systems & the DSPy Framework** <br> Omar Khattab, Databricks |  |          
| Oct 14 | **Agents for Software Development** <br> Graham Neubig, Carnegie Mellon University |  |          
| Oct 21 | **Agent for Workflow Applications** <br> Nicolas Chapados, ServiceNow |  |          
| Oct 28 | **Stronger Together: Marrying Neural Networks with Traditional Symbolic Decision-Making** <br> Yuandong Tian, Meta AI (FAIR) |  |          
| Nov 4 | **Foundation Agent** <br> Jim Fan, NVIDIA |  |          
| Nov 11 | **No Class - Veteran's Day** |          |          
| Nov 18 | **Cybersecurity, agents, and open-source** <br> Percy Liang, Stanford University |  |          
| Nov 25 | **LLM Agent Safety** <br> Dawn Song, UC Berkeley |  |          
| Dec 2 | **TBA** <br> Ben Mann, Anthropic |  |   
